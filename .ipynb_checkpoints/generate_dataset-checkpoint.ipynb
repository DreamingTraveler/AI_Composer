{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 datasets/bach\\bwv10.7.mxl\n",
      "3 datasets/bach\\bwv101.7.mxl\n",
      "4 datasets/bach\\bwv102.7.mxl\n",
      "5 datasets/bach\\bwv103.6.mxl\n",
      "6 datasets/bach\\bwv104.6.mxl\n",
      "7 datasets/bach\\bwv108.6.mxl\n",
      "8 datasets/bach\\bwv11.6.mxl\n",
      "9 datasets/bach\\bwv110.7.mxl\n",
      "10 datasets/bach\\bwv111.6.mxl\n",
      "12 datasets/bach\\bwv112.5.mxl\n",
      "13 datasets/bach\\bwv113.8.mxl\n",
      "14 datasets/bach\\bwv114.7.mxl\n",
      "15 datasets/bach\\bwv115.6.mxl\n",
      "16 datasets/bach\\bwv116.6.mxl\n",
      "17 datasets/bach\\bwv117.4.mxl\n",
      "18 datasets/bach\\bwv119.9.mxl\n",
      "20 datasets/bach\\bwv120.6.mxl\n",
      "22 datasets/bach\\bwv121.6.mxl\n",
      "23 datasets/bach\\bwv122.6.mxl\n",
      "24 datasets/bach\\bwv123.6.mxl\n",
      "26 datasets/bach\\bwv125.6.mxl\n",
      "27 datasets/bach\\bwv126.6.mxl\n",
      "28 datasets/bach\\bwv127.5.mxl\n",
      "30 datasets/bach\\bwv13.6.mxl\n",
      "32 datasets/bach\\bwv135.6.mxl\n",
      "35 datasets/bach\\bwv139.6.mxl\n",
      "36 datasets/bach\\bwv14.5.mxl\n",
      "37 datasets/bach\\bwv140.7.mxl\n",
      "38 datasets/bach\\bwv144.3.mxl\n",
      "39 datasets/bach\\bwv144.6.mxl\n",
      "40 datasets/bach\\bwv145-a.mxl\n",
      "41 datasets/bach\\bwv145.5.mxl\n",
      "42 datasets/bach\\bwv146.8.mxl\n",
      "43 datasets/bach\\bwv148.6.mxl\n",
      "45 datasets/bach\\bwv151.5.mxl\n",
      "46 datasets/bach\\bwv153.1.mxl\n",
      "47 datasets/bach\\bwv153.5.mxl\n",
      "48 datasets/bach\\bwv153.9.mxl\n",
      "49 datasets/bach\\bwv154.3.mxl\n",
      "50 datasets/bach\\bwv154.8.mxl\n",
      "51 datasets/bach\\bwv155.5.mxl\n",
      "52 datasets/bach\\bwv156.6.mxl\n",
      "53 datasets/bach\\bwv157.5.mxl\n",
      "54 datasets/bach\\bwv158.4.mxl\n",
      "55 datasets/bach\\bwv159.5.mxl\n",
      "56 datasets/bach\\bwv16.6.mxl\n",
      "58 datasets/bach\\bwv162.6-lpz.mxl\n",
      "59 datasets/bach\\bwv164.6.mxl\n",
      "60 datasets/bach\\bwv165.6.mxl\n",
      "61 datasets/bach\\bwv166.6.mxl\n",
      "62 datasets/bach\\bwv168.6.mxl\n",
      "63 datasets/bach\\bwv169.7.mxl\n",
      "64 datasets/bach\\bwv17.7.mxl\n",
      "67 datasets/bach\\bwv174.5.mxl\n",
      "69 datasets/bach\\bwv176.6.mxl\n",
      "70 datasets/bach\\bwv177.5.mxl\n",
      "71 datasets/bach\\bwv178.7.mxl\n",
      "72 datasets/bach\\bwv179.6.mxl\n",
      "73 datasets/bach\\bwv18.5-lz.mxl\n",
      "74 datasets/bach\\bwv18.5-w.mxl\n",
      "75 datasets/bach\\bwv180.7.mxl\n",
      "76 datasets/bach\\bwv183.5.mxl\n",
      "77 datasets/bach\\bwv184.5.mxl\n",
      "79 datasets/bach\\bwv187.7.mxl\n",
      "80 datasets/bach\\bwv188.6.mxl\n",
      "83 datasets/bach\\bwv190.7.mxl\n",
      "84 datasets/bach\\bwv194.12.mxl\n",
      "85 datasets/bach\\bwv194.6.mxl\n",
      "87 datasets/bach\\bwv197.10.mxl\n",
      "88 datasets/bach\\bwv197.5.mxl\n",
      "89 datasets/bach\\bwv197.7-a.mxl\n",
      "90 datasets/bach\\bwv2.6.mxl\n",
      "91 datasets/bach\\bwv20.11.mxl\n",
      "92 datasets/bach\\bwv20.7.mxl\n",
      "93 datasets/bach\\bwv226.2.mxl\n",
      "94 datasets/bach\\bwv227.1.mxl\n",
      "95 datasets/bach\\bwv227.11.mxl\n",
      "97 datasets/bach\\bwv227.7.mxl\n",
      "98 datasets/bach\\bwv229.2.mxl\n",
      "99 datasets/bach\\bwv244.10.mxl\n",
      "100 datasets/bach\\bwv244.15.mxl\n",
      "101 datasets/bach\\bwv244.17.mxl\n",
      "102 datasets/bach\\bwv244.25.mxl\n",
      "103 datasets/bach\\bwv244.29-a.mxl\n",
      "104 datasets/bach\\bwv244.3.mxl\n",
      "105 datasets/bach\\bwv244.32.mxl\n",
      "106 datasets/bach\\bwv244.37.mxl\n",
      "107 datasets/bach\\bwv244.40.mxl\n",
      "108 datasets/bach\\bwv244.44.mxl\n",
      "109 datasets/bach\\bwv244.46.mxl\n",
      "110 datasets/bach\\bwv244.54.mxl\n",
      "111 datasets/bach\\bwv244.62.mxl\n",
      "112 datasets/bach\\bwv245.11.mxl\n",
      "113 datasets/bach\\bwv245.14.mxl\n",
      "114 datasets/bach\\bwv245.15.mxl\n",
      "115 datasets/bach\\bwv245.17.mxl\n",
      "116 datasets/bach\\bwv245.22.mxl\n",
      "117 datasets/bach\\bwv245.26.mxl\n",
      "118 datasets/bach\\bwv245.28.mxl\n",
      "119 datasets/bach\\bwv245.3.mxl\n",
      "120 datasets/bach\\bwv245.37.mxl\n",
      "121 datasets/bach\\bwv245.40.mxl\n",
      "122 datasets/bach\\bwv245.5.mxl\n",
      "123 datasets/bach\\bwv248.12-2.mxl\n",
      "126 datasets/bach\\bwv248.23-s.mxl\n",
      "127 datasets/bach\\bwv248.28.mxl\n",
      "128 datasets/bach\\bwv248.33-3.mxl\n",
      "129 datasets/bach\\bwv248.35-3.mxl\n",
      "132 datasets/bach\\bwv248.42-s.mxl\n",
      "133 datasets/bach\\bwv248.46-5.mxl\n",
      "134 datasets/bach\\bwv248.5.mxl\n",
      "135 datasets/bach\\bwv248.53-5.mxl\n",
      "138 datasets/bach\\bwv248.64-s.mxl\n",
      "141 datasets/bach\\bwv25.6.mxl\n",
      "145 datasets/bach\\bwv253.mxl\n",
      "146 datasets/bach\\bwv254.mxl\n",
      "147 datasets/bach\\bwv255.mxl\n",
      "148 datasets/bach\\bwv256.mxl\n",
      "149 datasets/bach\\bwv257.mxl\n",
      "150 datasets/bach\\bwv258.mxl\n",
      "151 datasets/bach\\bwv259.mxl\n",
      "152 datasets/bach\\bwv26.6.mxl\n",
      "153 datasets/bach\\bwv260.mxl\n",
      "154 datasets/bach\\bwv261.mxl\n",
      "155 datasets/bach\\bwv262.mxl\n",
      "156 datasets/bach\\bwv263.mxl\n",
      "157 datasets/bach\\bwv264.mxl\n",
      "158 datasets/bach\\bwv265.mxl\n",
      "159 datasets/bach\\bwv266.mxl\n",
      "160 datasets/bach\\bwv268.mxl\n",
      "161 datasets/bach\\bwv269.mxl\n",
      "163 datasets/bach\\bwv270.mxl\n",
      "164 datasets/bach\\bwv271.mxl\n",
      "165 datasets/bach\\bwv272.mxl\n",
      "166 datasets/bach\\bwv273.mxl\n",
      "167 datasets/bach\\bwv276.mxl\n",
      "168 datasets/bach\\bwv277.mxl\n",
      "169 datasets/bach\\bwv278.mxl\n",
      "170 datasets/bach\\bwv279.mxl\n",
      "171 datasets/bach\\bwv28.6.mxl\n",
      "172 datasets/bach\\bwv280.mxl\n",
      "173 datasets/bach\\bwv281.mxl\n",
      "174 datasets/bach\\bwv282.mxl\n",
      "175 datasets/bach\\bwv283.mxl\n",
      "176 datasets/bach\\bwv284.mxl\n",
      "177 datasets/bach\\bwv285.mxl\n",
      "178 datasets/bach\\bwv286.mxl\n",
      "179 datasets/bach\\bwv287.mxl\n",
      "180 datasets/bach\\bwv288.mxl\n",
      "181 datasets/bach\\bwv289.mxl\n",
      "183 datasets/bach\\bwv290.mxl\n",
      "184 datasets/bach\\bwv291.mxl\n",
      "185 datasets/bach\\bwv292.mxl\n",
      "186 datasets/bach\\bwv293.mxl\n",
      "187 datasets/bach\\bwv294.mxl\n",
      "188 datasets/bach\\bwv295.mxl\n",
      "189 datasets/bach\\bwv296.mxl\n",
      "190 datasets/bach\\bwv297.mxl\n",
      "191 datasets/bach\\bwv298.mxl\n",
      "192 datasets/bach\\bwv299.mxl\n",
      "193 datasets/bach\\bwv3.6.mxl\n",
      "194 datasets/bach\\bwv30.6.mxl\n",
      "195 datasets/bach\\bwv300.mxl\n",
      "196 datasets/bach\\bwv301.mxl\n",
      "197 datasets/bach\\bwv302.mxl\n",
      "198 datasets/bach\\bwv303.mxl\n",
      "199 datasets/bach\\bwv304.mxl\n",
      "200 datasets/bach\\bwv305.mxl\n",
      "201 datasets/bach\\bwv306.mxl\n",
      "202 datasets/bach\\bwv307.mxl\n",
      "203 datasets/bach\\bwv308.mxl\n",
      "204 datasets/bach\\bwv309.mxl\n",
      "206 datasets/bach\\bwv310.mxl\n",
      "207 datasets/bach\\bwv311.mxl\n",
      "208 datasets/bach\\bwv312.mxl\n",
      "209 datasets/bach\\bwv313.mxl\n",
      "210 datasets/bach\\bwv314.mxl\n",
      "211 datasets/bach\\bwv315.mxl\n",
      "212 datasets/bach\\bwv316.mxl\n",
      "213 datasets/bach\\bwv317.mxl\n",
      "214 datasets/bach\\bwv318.mxl\n",
      "215 datasets/bach\\bwv319.mxl\n",
      "216 datasets/bach\\bwv32.6.mxl\n",
      "217 datasets/bach\\bwv320.mxl\n",
      "218 datasets/bach\\bwv321.mxl\n",
      "219 datasets/bach\\bwv322.mxl\n",
      "220 datasets/bach\\bwv323.mxl\n",
      "221 datasets/bach\\bwv324.mxl\n",
      "222 datasets/bach\\bwv325.mxl\n",
      "223 datasets/bach\\bwv326.mxl\n",
      "224 datasets/bach\\bwv327.mxl\n",
      "225 datasets/bach\\bwv328.mxl\n",
      "226 datasets/bach\\bwv329.mxl\n",
      "227 datasets/bach\\bwv33.6.mxl\n",
      "228 datasets/bach\\bwv330.mxl\n",
      "229 datasets/bach\\bwv331.mxl\n",
      "230 datasets/bach\\bwv332.mxl\n",
      "231 datasets/bach\\bwv333.mxl\n",
      "232 datasets/bach\\bwv334.mxl\n",
      "233 datasets/bach\\bwv335.mxl\n",
      "234 datasets/bach\\bwv336.mxl\n",
      "235 datasets/bach\\bwv337.mxl\n",
      "236 datasets/bach\\bwv338.mxl\n",
      "237 datasets/bach\\bwv339.mxl\n",
      "238 datasets/bach\\bwv340.mxl\n",
      "239 datasets/bach\\bwv341.mxl\n",
      "240 datasets/bach\\bwv342.mxl\n",
      "241 datasets/bach\\bwv343.mxl\n",
      "242 datasets/bach\\bwv344.mxl\n",
      "243 datasets/bach\\bwv345.mxl\n",
      "244 datasets/bach\\bwv346.mxl\n",
      "245 datasets/bach\\bwv347.mxl\n",
      "246 datasets/bach\\bwv348.mxl\n",
      "247 datasets/bach\\bwv349.mxl\n",
      "248 datasets/bach\\bwv350.mxl\n",
      "249 datasets/bach\\bwv351.mxl\n",
      "250 datasets/bach\\bwv352.mxl\n",
      "251 datasets/bach\\bwv353.mxl\n",
      "252 datasets/bach\\bwv354.mxl\n",
      "253 datasets/bach\\bwv355.mxl\n",
      "254 datasets/bach\\bwv356.mxl\n",
      "255 datasets/bach\\bwv357.mxl\n",
      "256 datasets/bach\\bwv358.mxl\n",
      "257 datasets/bach\\bwv359.mxl\n",
      "258 datasets/bach\\bwv36.4-2.mxl\n",
      "259 datasets/bach\\bwv36.8-2.mxl\n",
      "260 datasets/bach\\bwv360.mxl\n",
      "261 datasets/bach\\bwv361.mxl\n",
      "262 datasets/bach\\bwv362.mxl\n",
      "263 datasets/bach\\bwv363.mxl\n",
      "264 datasets/bach\\bwv364.mxl\n",
      "265 datasets/bach\\bwv365.mxl\n",
      "266 datasets/bach\\bwv366.mxl\n",
      "267 datasets/bach\\bwv367.mxl\n",
      "268 datasets/bach\\bwv368.mxl\n",
      "269 datasets/bach\\bwv369.mxl\n",
      "270 datasets/bach\\bwv37.6.mxl\n",
      "271 datasets/bach\\bwv370.mxl\n",
      "272 datasets/bach\\bwv371.mxl\n",
      "273 datasets/bach\\bwv372.mxl\n",
      "274 datasets/bach\\bwv373.mxl\n",
      "275 datasets/bach\\bwv374.mxl\n",
      "276 datasets/bach\\bwv375.mxl\n",
      "277 datasets/bach\\bwv376.mxl\n",
      "278 datasets/bach\\bwv377.mxl\n",
      "279 datasets/bach\\bwv378.mxl\n",
      "280 datasets/bach\\bwv379.mxl\n",
      "281 datasets/bach\\bwv38.6.mxl\n",
      "282 datasets/bach\\bwv380.mxl\n",
      "283 datasets/bach\\bwv381.mxl\n",
      "284 datasets/bach\\bwv382.mxl\n",
      "285 datasets/bach\\bwv383.mxl\n",
      "286 datasets/bach\\bwv384.mxl\n",
      "287 datasets/bach\\bwv385.mxl\n",
      "288 datasets/bach\\bwv386.mxl\n",
      "289 datasets/bach\\bwv387.mxl\n",
      "290 datasets/bach\\bwv389.mxl\n",
      "291 datasets/bach\\bwv39.7.mxl\n",
      "292 datasets/bach\\bwv390.mxl\n",
      "293 datasets/bach\\bwv391.mxl\n",
      "294 datasets/bach\\bwv392.mxl\n",
      "295 datasets/bach\\bwv393.mxl\n",
      "296 datasets/bach\\bwv394.mxl\n",
      "297 datasets/bach\\bwv395.mxl\n",
      "298 datasets/bach\\bwv396.mxl\n",
      "299 datasets/bach\\bwv397.mxl\n",
      "300 datasets/bach\\bwv398.mxl\n",
      "301 datasets/bach\\bwv399.mxl\n",
      "302 datasets/bach\\bwv4.8.mxl\n",
      "303 datasets/bach\\bwv40.3.mxl\n",
      "304 datasets/bach\\bwv40.6.mxl\n",
      "305 datasets/bach\\bwv40.8.mxl\n",
      "306 datasets/bach\\bwv400.mxl\n",
      "307 datasets/bach\\bwv401.mxl\n",
      "308 datasets/bach\\bwv402.mxl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309 datasets/bach\\bwv403.mxl\n",
      "310 datasets/bach\\bwv404.mxl\n",
      "311 datasets/bach\\bwv405.mxl\n",
      "312 datasets/bach\\bwv406.mxl\n",
      "313 datasets/bach\\bwv407.mxl\n",
      "314 datasets/bach\\bwv408.mxl\n",
      "316 datasets/bach\\bwv410.mxl\n",
      "317 datasets/bach\\bwv411.mxl\n",
      "318 datasets/bach\\bwv412.mxl\n",
      "319 datasets/bach\\bwv413.mxl\n",
      "320 datasets/bach\\bwv414.mxl\n",
      "321 datasets/bach\\bwv415.mxl\n",
      "322 datasets/bach\\bwv416.mxl\n",
      "323 datasets/bach\\bwv417.mxl\n",
      "324 datasets/bach\\bwv418.mxl\n",
      "325 datasets/bach\\bwv419.mxl\n",
      "326 datasets/bach\\bwv42.7.mxl\n",
      "327 datasets/bach\\bwv420.mxl\n",
      "328 datasets/bach\\bwv421.mxl\n",
      "329 datasets/bach\\bwv422.mxl\n",
      "330 datasets/bach\\bwv423.mxl\n",
      "331 datasets/bach\\bwv424.mxl\n",
      "332 datasets/bach\\bwv425.mxl\n",
      "333 datasets/bach\\bwv426.mxl\n",
      "334 datasets/bach\\bwv427.mxl\n",
      "335 datasets/bach\\bwv428.mxl\n",
      "336 datasets/bach\\bwv429.mxl\n",
      "337 datasets/bach\\bwv43.11.mxl\n",
      "338 datasets/bach\\bwv430.mxl\n",
      "339 datasets/bach\\bwv431.mxl\n",
      "340 datasets/bach\\bwv432.mxl\n",
      "341 datasets/bach\\bwv433.mxl\n",
      "342 datasets/bach\\bwv434.mxl\n",
      "343 datasets/bach\\bwv435.mxl\n",
      "344 datasets/bach\\bwv436.mxl\n",
      "345 datasets/bach\\bwv437.mxl\n",
      "346 datasets/bach\\bwv438.mxl\n",
      "347 datasets/bach\\bwv44.7.mxl\n",
      "348 datasets/bach\\bwv45.7.mxl\n",
      "349 datasets/bach\\bwv47.5.mxl\n",
      "350 datasets/bach\\bwv48.3.mxl\n",
      "351 datasets/bach\\bwv48.7.mxl\n",
      "352 datasets/bach\\bwv5.7.mxl\n",
      "354 datasets/bach\\bwv55.5.mxl\n",
      "355 datasets/bach\\bwv56.5.mxl\n",
      "356 datasets/bach\\bwv57.8.mxl\n",
      "358 datasets/bach\\bwv6.6.mxl\n",
      "359 datasets/bach\\bwv60.5.mxl\n",
      "360 datasets/bach\\bwv64.2.mxl\n",
      "362 datasets/bach\\bwv64.8.mxl\n",
      "363 datasets/bach\\bwv65.2.mxl\n",
      "364 datasets/bach\\bwv65.7.mxl\n",
      "365 datasets/bach\\bwv66.6.mxl\n",
      "366 datasets/bach\\bwv67.7.mxl\n",
      "367 datasets/bach\\bwv7.7.mxl\n",
      "369 datasets/bach\\bwv70.7.mxl\n",
      "370 datasets/bach\\bwv72.6.mxl\n",
      "371 datasets/bach\\bwv73.5.mxl\n",
      "372 datasets/bach\\bwv74.8.mxl\n",
      "373 datasets/bach\\bwv77.6.mxl\n",
      "374 datasets/bach\\bwv78.7.mxl\n",
      "378 datasets/bach\\bwv80.8.mxl\n",
      "379 datasets/bach\\bwv81.7.mxl\n",
      "380 datasets/bach\\bwv83.5.mxl\n",
      "381 datasets/bach\\bwv84.5.mxl\n",
      "383 datasets/bach\\bwv85.6.mxl\n",
      "384 datasets/bach\\bwv86.6.mxl\n",
      "385 datasets/bach\\bwv87.7.mxl\n",
      "386 datasets/bach\\bwv88.7.mxl\n",
      "387 datasets/bach\\bwv89.6.mxl\n",
      "388 datasets/bach\\bwv9.7.mxl\n",
      "389 datasets/bach\\bwv90.5.mxl\n",
      "391 datasets/bach\\bwv92.9.mxl\n",
      "392 datasets/bach\\bwv93.7.mxl\n",
      "393 datasets/bach\\bwv94.8.mxl\n",
      "395 datasets/bach\\bwv96.6.mxl\n",
      "397 datasets/bach\\bwv99.6.mxl\n",
      "352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 352/352 [00:53<00:00,  6.05it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5f5cfedd66c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mload_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-5f5cfedd66c7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m     \u001b[0mload_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-5f5cfedd66c7>\u001b[0m in \u001b[0;36mload_files\u001b[1;34m()\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mdataset_notes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_notes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mchorale_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnotes\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchorale_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes_to_piano_roll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_notes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[0mnotes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchorale_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchorale_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-5f5cfedd66c7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mdataset_notes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_notes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0mchorale_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnotes\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchorale_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes_to_piano_roll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_notes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[0mnotes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchorale_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchorale_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-5f5cfedd66c7>\u001b[0m in \u001b[0;36mnotes_to_piano_roll\u001b[1;34m(dataset_notes)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mchorale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_notes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchorale_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparts_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mpiano_roll_notes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_symbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchorale\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[0mpiano_roll_notes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpiano_roll_notes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mpiano_roll_notes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_note_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpiano_roll_notes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"to_index\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparts_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from music21 import *\n",
    "from glob import glob\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, RepeatVector, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%run lstm_model.ipynb\n",
    "np.set_printoptions(threshold=1000000)\n",
    "bach_chorale_path = 'datasets/bach2'\n",
    "parts_index = [0,1,2,3]\n",
    "#parts_index = [0,1]\n",
    "note_type = set()\n",
    "\"\"\"\n",
    "note_type:\n",
    "0-127 : note pitch\n",
    "128: slur-1st-part\n",
    "129: slur-2nd-part\n",
    "130: slur-3rd-part\n",
    "131: slur-4th-part\n",
    "132: rest\n",
    "133: start symbol\n",
    "134: end symbol\n",
    "\"\"\"\n",
    "\n",
    "def filter_files(files):\n",
    "    file_list = []\n",
    "    file_count = 0\n",
    "    for i, file in enumerate(files, 1):\n",
    "        s = converter.parse(file)\n",
    "        if len(s.parts) == len(parts_index):\n",
    "            print(i, file)\n",
    "            file_count += 1\n",
    "            file_list.append(file)\n",
    "    return file_list, file_count\n",
    "\n",
    "def chorale_to_inputs(s,i):\n",
    "    inputs = []\n",
    "    for n in s.parts[i].flat.notes:\n",
    "#         if n.isNote:\n",
    "#             print(n.nameWithOctave, int(4 * n.quarterLength), n.offset)\n",
    "#         else:\n",
    "#             print(n.pitchNames, int(4 * n.quarterLength), n.offset)\n",
    "        #print(n.expressions)\n",
    "        if n.isNote:\n",
    "            inputs.append([n.pitch.midi])\n",
    "            note_type.add(frozenset([n.pitch.midi]))\n",
    "        elif n.isChord:\n",
    "            inputs.append([_note.pitch.midi for _note in n])\n",
    "            note_type.add(frozenset([_note.pitch.midi for _note in n]))\n",
    "        l = n.quarterLength\n",
    "#         if l == 0:\n",
    "#             l = 1\n",
    "        for j in range(1, int(4 * l)):\n",
    "            if i == 0:\n",
    "                inputs.append([128])\n",
    "                note_type.add(frozenset([128]))\n",
    "            elif i == 1:\n",
    "                inputs.append([129])\n",
    "                note_type.add(frozenset([129]))\n",
    "            elif i == 2:\n",
    "                inputs.append([130])\n",
    "                note_type.add(frozenset([130]))\n",
    "            elif i == 3:\n",
    "                inputs.append([131])\n",
    "                note_type.add(frozenset([131]))\n",
    "    return inputs\n",
    "\n",
    "def make_time_metadata(file):\n",
    "    chorale = converter.parse(file)\n",
    "    chorale_length = int(chorale.parts[0].duration.quarterLength * 4)\n",
    "    time_metadata = np.zeros((chorale_length, ))\n",
    "    \n",
    "    for i in range(0, chorale_length):\n",
    "        time_metadata[i] = i + 1\n",
    "    return np.array(time_metadata, dtype=np.int32)\n",
    "\n",
    "def append_notes(max_length, part_i_length, part_i_input):\n",
    "    note_type.add(frozenset([132]))# 132-->note.Rest\n",
    "    for num_appended_notes in range(max_length - part_i_length):\n",
    "        part_i_input.append([132])\n",
    "    return part_i_input\n",
    "\n",
    "def check_parts_length(parts_length, inputs):\n",
    "    max_length = max(parts_length)\n",
    "    for i in parts_index:\n",
    "        if parts_length[i] < max_length:\n",
    "            inputs[i] = append_notes(max_length, parts_length[i], inputs[i])\n",
    "                \n",
    "def make_dataset(file_list):\n",
    "    X = []\n",
    "    time_metadata = []\n",
    "    for file in tqdm(file_list):\n",
    "        s = converter.parse(file)\n",
    "        \n",
    "        inputs = []\n",
    "        parts_length = []\n",
    "        time_metadata.append(make_time_metadata(file))\n",
    "        for i in parts_index:\n",
    "            part_input = chorale_to_inputs(s,i)\n",
    "            parts_length.append(len(part_input))\n",
    "            inputs.append(part_input)\n",
    "        check_parts_length(parts_length, inputs)\n",
    "        np_inputs = np.array(inputs)\n",
    "        X.append(np_inputs)\n",
    "    #X.reshape(X.shape[1:])\n",
    "    #print(time_metadata)\n",
    "    return X\n",
    "def generator_X(notes):\n",
    "    t = 0\n",
    "    while True:\n",
    "        X = []\n",
    "        if t < notes.shape[0] - 16:\n",
    "            X.append(notes[t:t+16])\n",
    "        else: \n",
    "            t = 0\n",
    "            continue\n",
    "        t += 16\n",
    "        X = np.array(X)\n",
    "        yield (X)\n",
    "def generate_notes(lstm_model, X):\n",
    "    output_indices = []\n",
    "    for i in range(len(parts_index)):\n",
    "        model = load_model(\"models/bach\"+str(i)+\".h5\")\n",
    "#     model = load_model(lstm_model.name+\".h5\")\n",
    "        gen = ((X) for (X) in generator_X(lstm_model.X))\n",
    "#     predict_list = model.predict(X, batch_size=32)\n",
    "        predict_list = model.predict_generator(gen, steps=300)\n",
    "        part_notes = []\n",
    "        for time in range(predict_list.shape[0]):\n",
    "            for note_index in range(predict_list.shape[1]):\n",
    "                part_notes.append(np.argmax(predict_list[time][note_index]))\n",
    "        output_indices.append(part_notes)\n",
    "    output_indices = np.array(output_indices)\n",
    "    output_chorale = index_note_transform(output_indices, \"to_note\", len(parts_index))\n",
    "    #output_indices = np.transpose(output_indices)\n",
    "   # output_chorale = np.transpose(output_chorale)\n",
    "    midi = chorale_to_midi(output_chorale)\n",
    "    print(output_chorale)\n",
    "    return midi\n",
    "\n",
    "# def insert_note_chord(n, d, new_note, part):\n",
    "    \n",
    "# def notes_to_midi(n, d, new_note, part):\n",
    "#     if (len(n) < 2): # note or rest\n",
    "#         if n[0] == 132:\n",
    "#             part.append(note.Rest())\n",
    "#         elif n[0] < 128:\n",
    "#             if d > 0:\n",
    "#                 new_note.duration = duration.Duration(d / 4)\n",
    "#                 part.append(new_note)\n",
    "#                 d = 1\n",
    "#                 new_note = note.Note(n[0])\n",
    "#             else:\n",
    "#                 d += 1\n",
    "#     else: # chord\n",
    "#         if d > 0:\n",
    "#             new_note.duration = duration.Duration(d / 4)\n",
    "#             part.append(new_note)\n",
    "#             d = 1\n",
    "#             new_note = chord.Chord(n)\n",
    "#         else:\n",
    "#             d += 1\n",
    "def chorale_to_midi(chorale):\n",
    "    score = stream.Score()\n",
    "    for i, chorale_part in enumerate(chorale):\n",
    "        part = stream.Part(id=i)\n",
    "        d = 0\n",
    "        new_note = note.Rest()\n",
    "        for sound in chorale_part:\n",
    "            sound = [n for n in sound]\n",
    "            if (len(sound) < 2): # note or rest\n",
    "                if sound[0] == 132:\n",
    "                    part.append(note.Rest())\n",
    "                elif sound[0] < 128:\n",
    "                    if d > 0:\n",
    "                        new_note.duration = duration.Duration(d / 4)\n",
    "                        part.append(new_note)\n",
    "                    d = 1\n",
    "                    new_note = note.Note(sound[0])\n",
    "                else:\n",
    "                    d += 1\n",
    "            else: # chord\n",
    "                if d > 0:\n",
    "                    new_note.duration = duration.Duration(d / 4)\n",
    "                    part.append(new_note)\n",
    "                d = 1\n",
    "                new_note = chord.Chord(sound)\n",
    "            \n",
    "        new_note.duration = duration.Duration(d / 4)\n",
    "        part.append(new_note)\n",
    "        score.insert(part)\n",
    "    return score\n",
    "def make_note_type_list():\n",
    "    note_type_list = []\n",
    "    for i in note_type:\n",
    "        note_type_list.append(i)\n",
    "    return sorted(note_type_list)\n",
    "# def transform_note_to_index(notes):\n",
    "#     for time in range(notes.shape[0]):\n",
    "#         for p_index in range(4):\n",
    "#             notes[time][p_index] = note_dict[notes[time][p_index]]\n",
    "#     return notes\n",
    "def index_note_transform(inputs, option, pn):\n",
    "    transformed_inputs = []\n",
    "    if option == \"to_note\":\n",
    "        note_dict = dict((index, note) for index, note in enumerate(note_type))\n",
    "    elif option == \"to_index\":\n",
    "        note_dict = dict((note, index) for index, note in enumerate(note_type))\n",
    "    \n",
    "    for p_index in range(pn):\n",
    "        transformed_part = []\n",
    "        for n in range(inputs.shape[1]):\n",
    "            for keys in note_dict:\n",
    "                if option == \"to_note\":\n",
    "                    if inputs[p_index][n] == keys:\n",
    "                        transformed_part.append(note_dict[keys])\n",
    "                elif option == \"to_index\":\n",
    "                    if frozenset(inputs[p_index][n]) == keys:\n",
    "                        transformed_part.append(note_dict[keys])\n",
    "        transformed_inputs.append(transformed_part)\n",
    "    return np.array(transformed_inputs)\n",
    "def notes_to_piano_roll(dataset_notes):\n",
    "    start_symbol = np.full((16, 1),133)\n",
    "    end_symbol = np.full((16, 1),134)\n",
    "    note_type.add(frozenset([133]))\n",
    "    note_type.add(frozenset([134]))\n",
    "    for chorale_index in range(len(dataset_notes)):\n",
    "        piano_roll_notes = []\n",
    "        chorale = np.array(dataset_notes[chorale_index])\n",
    "        for i in range(len(parts_index)):\n",
    "            piano_roll_notes.append(np.concatenate((start_symbol, chorale[i], end_symbol)))\n",
    "        piano_roll_notes = np.array(piano_roll_notes)\n",
    "        piano_roll_notes = index_note_transform(piano_roll_notes, \"to_index\", len(parts_index))\n",
    "        piano_roll_notes = np.transpose(piano_roll_notes)\n",
    "        #piano_roll_notes = index_note_transform(transposed_chorale, \"to_index\", 4)\n",
    "        yield piano_roll_notes\n",
    "def notes_to_onehot(notes):\n",
    "    note_dict = note_dict = dict((index, note) for index, note in enumerate(note_type))\n",
    "    onehot = []\n",
    "    print(note_dict)\n",
    "    for i, n in enumerate(notes):\n",
    "        a = []\n",
    "        for note in n:\n",
    "            a.append(np.array(note == np.arange(0, len(note_dict)), dtype=np.int32))\n",
    "        onehot.append(a)\n",
    "    return np.array(onehot)\n",
    "def part_notes_to_onehot(notes):\n",
    "    note_dict = dict((index, note) for index, note in enumerate(note_type))\n",
    "    onehot = []\n",
    "    for i, n in enumerate(notes):\n",
    "        a = np.zeros(len(note_dict,),dtype=np.int32)\n",
    "        for note in n:\n",
    "            a[note] = 1\n",
    "        onehot.append(a)\n",
    "    return np.array(onehot)\n",
    "\n",
    "def load_files():\n",
    "    if os.path.exists(bach_chorale_path):\n",
    "#         file_list = filter_files(glob(bach_chorale_path))\n",
    "        file_list, num_file = filter_files(glob(bach_chorale_path + '/*.mxl') +\n",
    "                                 glob(bach_chorale_path + '/*.mid'))\n",
    "        print(num_file)\n",
    "        dataset_notes = make_dataset(file_list)\n",
    "        shuffle(dataset_notes)\n",
    "        chorale_list = [notes for chorale_index, notes in enumerate(notes_to_piano_roll(dataset_notes))]\n",
    "        notes = chorale_list[0]\n",
    "        for i, n in enumerate(chorale_list):\n",
    "            if i != 0:\n",
    "                notes = np.concatenate((notes, n))\n",
    "        print(notes.shape)\n",
    "        Y_onehot_notes = notes_to_onehot(notes)\n",
    "        X_onehot_notes = part_notes_to_onehot(notes)\n",
    "#         notes = notes[:,:,np.newaxis]\n",
    "        for i in range(len(parts_index)):\n",
    "            lstm_model = LSTM_Model(X=X_onehot_notes,Y=Y_onehot_notes,epochs=5, output_dim=len(note_type), name=\"bach\"+str(i))\n",
    "            gen = ((X,Y) for (X, Y) in lstm_model.generator(X_onehot_notes, Y_onehot_notes, i))\n",
    "            lstm_model.model2()\n",
    "            lstm_model.train_model(gen)\n",
    "\n",
    "        score = generate_notes(lstm_model, notes)\n",
    "                \n",
    "        output_file = str(lstm_model.epochs) + '-epochs_' + str(num_file) + '-samples.mid'\n",
    "        mf = midi.translate.music21ObjectToMidiFile(score)\n",
    "        mf.open(output_file, 'wb')\n",
    "        mf.write()\n",
    "        mf.close()\n",
    "        print(\"File \" + output_file + \" written\")\n",
    "    else:\n",
    "        print(\"The file path is wrong!!\")\n",
    "    \n",
    "def main():\n",
    "    load_files()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = [0,1,2,3,4,5,6,7,8]\n",
    "n = np.array(n)\n",
    "g = np.zeros((len(n),),dtype=np.int32)\n",
    "print(g)\n",
    "a = [0,5,7]\n",
    "for i in a:\n",
    "    print(np.array(i == np.arange(0, len(n) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2074653076684687,\n",
       " 0.16978126126545184,\n",
       " 0.19530057979859625,\n",
       " 0.2446219152457011,\n",
       " 0.2518720217835262]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_pro(x1,x2,y1,y2):\n",
    "    return (x1*y1)+(x2*y2)\n",
    "x = [1.4, 1.6]\n",
    "A1 = [1.5, 2.0, 1.6, 1.2, 1.5]\n",
    "A2 = [1.7, 1.9, 1.8, 1.5, 1.0]\n",
    "ans = []\n",
    "for i in range(5):\n",
    "    ans.append(inner_pro(x[0],x[1],A1[i],A2[i]) / (inner_pro(x[0],x[1],x[0],x[1]) * inner_pro(A1[i],A2[i],A1[i],A2[i])))\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "f = frozenset([1,2,3,4,5])\n",
    "for i in f:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
