{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, RepeatVector, Dropout, TimeDistributed\n",
    "\n",
    "class LSTM_Model():\n",
    "    def __init__(self, X=None, Y=None, num_units=200, epochs=10, batch_size=64,output_dim=None , name=\"\"):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.num_units = num_units\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.name = name\n",
    "        self.timesteps = 16 # one bar\n",
    "        self.output_dim = output_dim\n",
    "    def create_model(self):\n",
    "        print(\"create model...\")\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(self.num_units, input_shape=(self.timesteps, self.X.shape[-1]),\n",
    "                       return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(self.num_units, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(self.Y.shape[2], activation='softmax'))\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        model.summary()\n",
    "        model.save('models/' + self.name + '.h5')\n",
    "    def model2(self):\n",
    "        print(\"Another model...\")\n",
    "        \n",
    "        input_notes = Input(shape=(self.timesteps, self.X.shape[-1]))\n",
    "        rs = True\n",
    "        lstm = LSTM(200, return_sequences=rs, name=\"lstm_\" + str(1))(input_notes)\n",
    "        lstm = (Dropout(0.2))(lstm)\n",
    "\n",
    "        predict = Dense(200, activation='relu')(lstm)\n",
    "    #     output = Dense(len(note_type_arr), activation='softmax')(predict)\n",
    "        output = Dense(self.Y.shape[2], activation='softmax')(predict)\n",
    "\n",
    "        model = Model(input_notes, output)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "        model.summary()\n",
    "        model.save('models/' + self.name + '.h5')\n",
    "        #model.fit_generator(chorale_dict, steps_per_epoch=32, epochs=10)\n",
    "        #model.fit(X,X, batch_size=2, epochs=10)\n",
    "    def train_model(self, gen, test_gen):\n",
    "        print(\"train model...\")\n",
    "        model = load_model('models/' + self.name + '.h5')\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        model.fit_generator(gen, steps_per_epoch=256, epochs=self.epochs, validation_data=(test_gen), validation_steps=16)\n",
    "        model.save('models/' + self.name + '.h5')\n",
    "    def generator(self, notes, onehot_notes, part_i):\n",
    "        t = 0\n",
    "        while True:\n",
    "            X = []\n",
    "            Y = []\n",
    "            if t < notes.shape[0] - 16:\n",
    "                X.append(notes[t:t+16])\n",
    "                Y.append(onehot_notes[t:t+16,part_i,:])\n",
    "            else: \n",
    "                t = 0\n",
    "                continue\n",
    "            t += 16\n",
    "            X = np.array(X)\n",
    "            Y = np.array(Y)\n",
    "            yield (X,Y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
